{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec11169f",
   "metadata": {},
   "source": [
    "> Simple ResNet implementation for Fashion-MNIST (ResNet was originally used for ImageNet which contains 1,000 categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feefe6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from typing import Any, Union, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15c8eea",
   "metadata": {},
   "source": [
    "# Setup Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ece7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device: Any = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add4bf60",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9067d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import load_fashion_mnist\n",
    "\n",
    "mnist_path: str = os.path.join('..', '..', 'data')\n",
    "num_dataloader_workers: int = 4\n",
    "batch_size: int = 128\n",
    "\n",
    "# Resize images to 224x224 for AlexNet\n",
    "# This is not a well-method, but it is simple and works for demonstration purposes.\n",
    "train_iter, test_iter = load_fashion_mnist(batch_size, mnist_path, num_dataloader_workers, resize=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8e734",
   "metadata": {},
   "source": [
    "# ResNet-18 Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d8eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define A reshape layer which makes inputs compatible with Conv2d layers\n",
    "class Reshape(nn.Module):\n",
    "    def forward(self: Any, X: torch.Tensor) -> torch.Tensor:\n",
    "        return X.view(-1, 1, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define A Identity layer which does nothing\n",
    "class Identity(nn.Module):\n",
    "    def forward(self: Any, X: torch.Tensor) -> torch.Tensor:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d57cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Residual Sub-block\n",
    "class Residual18(nn.Module):\n",
    "    \"\"\"Residual Block for ResNet.\"\"\"\n",
    "    def __init__(self: Any, in_channels: int, out_channels: int, use_1x1conv: bool = False, strides: int = 1) -> None:\n",
    "        super(Residual18, self).__init__()\n",
    "        self.conv1: nn.Conv2d = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                            kernel_size=3, padding=1, stride=strides)\n",
    "        self.bn1: nn.BatchNorm2d = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.conv2: nn.Conv2d = nn.Conv2d(in_channels=out_channels, out_channels=out_channels,\n",
    "                                            kernel_size=3, padding=1, stride=1)\n",
    "        self.bn2: nn.BatchNorm2d = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.res_conn: Any = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                        kernel_size=1, stride=strides) if use_1x1conv else Identity()\n",
    "\n",
    "    def forward(self: Any, X: torch.Tensor) -> torch.Tensor:\n",
    "        Y: torch.Tensor = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        Y += self.res_conn(X)   # Residual connection\n",
    "        return F.relu(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42c54bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Residual Block\n",
    "def resnet18_block(in_channels: int, out_channels: int, num_residuals: int, first_block: bool = False) -> nn.Sequential:\n",
    "    \"\"\"Build a ResNet-18 block with multiple residual sub-blocks.\"\"\"\n",
    "    blks: List[Residual18] = []\n",
    "    for i in range(num_residuals):\n",
    "        if not first_block and i == 0:\n",
    "            blks.append(Residual18(in_channels=in_channels, out_channels=out_channels, use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blks.append(Residual18(in_channels=out_channels, out_channels=out_channels))\n",
    "    return blks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ddf08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ResNet-18 Architecture\n",
    "def resnet18(in_channels: int) -> nn.Sequential:\n",
    "    \"\"\"Create ResNet-18 model.\"\"\"\n",
    "    block1: nn.Sequential = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=7, padding=3, stride=2),\n",
    "        nn.BatchNorm2d(num_features=64), nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, padding=1, stride=2),\n",
    "    )\n",
    "    block2: nn.Sequential = resnet18_block(in_channels=64, out_channels=64, num_residuals=2, first_block=True)\n",
    "    block3: nn.Sequential = resnet18_block(in_channels=64, out_channels=128, num_residuals=2)\n",
    "    block4: nn.Sequential = resnet18_block(in_channels=128, out_channels=256, num_residuals=2)\n",
    "    block5: nn.Sequential = resnet18_block(in_channels=256, out_channels=512, num_residuals=2)\n",
    "    # Build the ResNet-18 model\n",
    "    resnet18: nn.Sequential = nn.Sequential(\n",
    "        Reshape(),\n",
    "        *block1, *block2, *block3, *block4, *block5,\n",
    "        nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=512, out_features=10)\n",
    "    )\n",
    "    return resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b1461",
   "metadata": {},
   "source": [
    "# ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c44aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ResNet Architecture\n",
    "resnet18_model: nn.Sequential = resnet18(in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15464391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "def init_weights(m: nn.Module) -> None:\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "_ = resnet18_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8674548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ResNet-18 model\n",
    "X: torch.Tensor = torch.rand(size=(10, 1, 224, 224), dtype=torch.float32)\n",
    "for layer in resnet18_model:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
    "    if isinstance(layer, nn.Sequential):\n",
    "        for sublayer in layer:\n",
    "            print('\\t', sublayer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005cf15f",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02152a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup hyper-parameters\n",
    "num_epochs: int = 10\n",
    "lr: float = 5e-2\n",
    "net: Any = resnet18_model.to(device)    # Move the model to the device (GPU or CPU)\n",
    "loss: Any = nn.CrossEntropyLoss(reduction='mean')   # PyTorch's CE contains softmax\n",
    "trainer: Any = torch.optim.SGD(net.parameters(), lr=lr)     # Use SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model training procedure\n",
    "from utils.trainer import train\n",
    "train(net, train_iter, test_iter, loss, num_epochs, trainer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08618b6",
   "metadata": {},
   "source": [
    "# Verify Train Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817b4e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import verify_trained_model\n",
    "verify_trained_model(net, test_iter, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

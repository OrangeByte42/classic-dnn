{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4afab691",
   "metadata": {},
   "source": [
    "> Implement Linear Regression from nothing, only rely on PyTorch's autograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb71e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from typing import Dict, Tuple, List, Iterator, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a151f32",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2fd990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['true_w', 'true_b', 'features', 'labels'])\n",
      "{'true_w': <class 'torch.Tensor'>, 'true_b': <class 'torch.Tensor'>, 'features': <class 'torch.Tensor'>, 'labels': <class 'torch.Tensor'>}\n"
     ]
    }
   ],
   "source": [
    "linreg_data_path: str = os.path.join('..', '..', 'data', 'linreg_data', 'linreg_data.pkl')\n",
    "\n",
    "with open(linreg_data_path, 'rb') as f:\n",
    "    data: Dict[str, torch.Tensor] = pickle.load(f)\n",
    "\n",
    "print(data.keys())\n",
    "print({key:value_type for key, value_type in zip(data.keys(), map(type, data.values()))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f9ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w, true_b = data['true_w'], data['true_b']\n",
    "features, labels = data['features'], data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24b0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size: int, features: torch.Tensor, labels: torch.Tensor) -> Iterator[Tuple[torch.Tensor, torch.Tensor]]:\n",
    "    \"\"\"Generate mini-batches of data.\"\"\"\n",
    "    num_samples: int = len(features)\n",
    "    indices: list = list(range(num_samples))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_indices: torch.Tensor = torch.tensor(indices[i:min(i + batch_size, num_samples)])\n",
    "        yield features[batch_indices], labels[batch_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad1bb8",
   "metadata": {},
   "source": [
    "# Build Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3845d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build linear regression model\n",
    "def linreg(X: torch.Tensor, w: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Linear regression model.\"\"\"\n",
    "    return X @ w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d572ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "w: torch.Tensor = torch.normal(0, 1e-1, size=(2, 1), requires_grad=True)\n",
    "b: torch.Tensor = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0868e67",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158437e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MSE as the loss function\n",
    "def mean_squared_loss(y_hat: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Mean squared error loss.\"\"\"\n",
    "    return ((y_hat - y) ** 2 / 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cb2e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sgd as the optimizer\n",
    "def sgd(params: List[torch.Tensor], lr: float) -> None:\n",
    "    \"\"\"Stochastic gradient descent.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6b47495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup hyper-parameters\n",
    "batch_size: int = 10\n",
    "lr: float = 3e-2\n",
    "num_epochs: int = 5\n",
    "net: Any = linreg\n",
    "loss: Any = mean_squared_loss\n",
    "trainer: Any = sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062d6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1， loss 0.037818\n",
      "epoch 2， loss 0.000136\n",
      "epoch 3， loss 0.000049\n",
      "epoch 4， loss 0.000048\n",
      "epoch 5， loss 0.000049\n"
     ]
    }
   ],
   "source": [
    "# Build model training procedure\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l: float = loss(net(X, w, b), y)\n",
    "        l.backward()\n",
    "        trainer([w, b], lr)\n",
    "    with torch.no_grad():\n",
    "        train_loss: float = loss(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}， loss {float(train_loss):f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48f758e",
   "metadata": {},
   "source": [
    "# Verify Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15c3c85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w estimated: tensor([ 1.9999, -3.4002], grad_fn=<ViewBackward0>), true w: tensor([ 2.0000, -3.4000])\n",
      "b estimated: tensor([4.2001], requires_grad=True), true b: tensor([4.2000])\n",
      "w and true_w difference: tensor([0.0001, 0.0002], grad_fn=<AbsBackward0>)\n",
      "b and true_b difference: tensor([0.0001], grad_fn=<AbsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"w estimated: {w.reshape(true_w.shape)}, true w: {true_w}\")\n",
    "print(f\"b estimated: {b}, true b: {true_b}\")\n",
    "\n",
    "print(f\"w and true_w difference: {torch.abs(true_w - w.reshape(true_w.shape))}\")\n",
    "print(f\"b and true_b difference: {torch.abs(true_b - b)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

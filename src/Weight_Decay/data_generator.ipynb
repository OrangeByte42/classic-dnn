{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "855d6bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from typing import Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c2b1e3",
   "metadata": {},
   "source": [
    "# For verifying how polynomial order effects fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2193b8c4",
   "metadata": {},
   "source": [
    "## Generate Random Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfe1ab4",
   "metadata": {},
   "source": [
    "Give variable $x$, use the third-order polynomials to generate train data and test data:\n",
    "$$\n",
    "y = 5 + 1.2x - 3.4\\frac{x^{2}}{2!} + 5.6\\frac{x^{3}}{3!} + \\epsilon\\ \\text{where}\\ \\epsilon \\sim \\mathcal{N}(0, {0.1}^2)\n",
    "$$\n",
    "- Noise term $\\epsilon$ obeys a normal distribution with a mean of $0$ and a standard deviation of $0.1$;\n",
    "- During optimization, it is often desirable to avoid very large gradient or loss values, that's why adjust the feature from $x^i$ to $\\frac{x^i}{i!}$, which can avoid large $i$ leads to very large exponential value;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf56b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some parameters\n",
    "max_degree: int = 160\n",
    "train_size, test_size = 50, 100\n",
    "true_w: np.ndarray = np.zeros(max_degree)\n",
    "true_w[0:4] = ([5, 1.2, -3.4, 5.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab87941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Random Data\n",
    "poly_features: np.ndarray = np.random.normal(size=(train_size + test_size, 1))\n",
    "np.random.shuffle(poly_features)\n",
    "\n",
    "poly_features = np.power(poly_features, np.arange(max_degree).reshape((1, -1)))\n",
    "for i in range(max_degree):\n",
    "    poly_features[:, i] /= math.gamma(i + 1)    # Divide by i!\n",
    "\n",
    "labels: np.ndarray = np.dot(poly_features, true_w)\n",
    "labels += np.random.normal(scale=1e-1, size=labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "314cafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to torch tensors\n",
    "true_w: torch.Tensor = torch.tensor(true_w, dtype=torch.float32)\n",
    "poly_features: torch.Tensor = torch.tensor(poly_features, dtype=torch.float32)\n",
    "labels: torch.Tensor = torch.tensor(labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c7f972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0000e+00, -1.2040e+00,  7.2485e-01, -2.9092e-01,  8.7569e-02,\n",
      "        -2.1087e-02,  4.2316e-03, -7.2786e-04,  1.0955e-04, -1.4655e-05,\n",
      "         1.7646e-06, -1.9314e-07,  1.9379e-08, -1.7949e-09,  1.5437e-10,\n",
      "        -1.2391e-11,  9.3243e-13, -6.6040e-14,  4.4175e-15, -2.7994e-16,\n",
      "         1.6853e-17, -9.6626e-19,  5.2882e-20, -2.7684e-21,  1.3888e-22,\n",
      "        -6.6888e-24,  3.0975e-25, -1.3813e-26,  5.9398e-28, -2.4661e-29,\n",
      "         9.8977e-31, -3.8443e-32,  1.4465e-33, -5.2775e-35,  1.8689e-36,\n",
      "        -6.4293e-38,  2.1503e-39, -6.9974e-41,  2.2169e-42, -6.8664e-44,\n",
      "         1.4013e-45, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "        -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "        -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "        -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "        -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "        -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "        -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "        -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "        -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "        -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "        -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "        -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
      "         0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
      "        -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00])\n",
      "tensor([-0.4919,  5.4837])\n"
     ]
    }
   ],
   "source": [
    "print(poly_features[0, :], labels[:2], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc21ea99",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aadfde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data: Dict[str, torch.Tensor] = {\n",
    "    'max_degree': max_degree,\n",
    "    'poly_features': poly_features,\n",
    "    'labels': labels,\n",
    "    'train_size': train_size,\n",
    "}\n",
    "\n",
    "save_path: str = os.path.join('..', '..', 'data', 'weight_decay')\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "with open(os.path.join(save_path, 'polynomials_order_data.pkl'), 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5660d6dd",
   "metadata": {},
   "source": [
    "# For verifying regularization technique -- weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5179d6",
   "metadata": {},
   "source": [
    "## Generate Random Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbe99a9",
   "metadata": {},
   "source": [
    "Give variable $x$, use the third-order polynomials to generate train data and test data:\n",
    "$$\n",
    "y = 0.05 + \\sum\\limits_{i=1}^{d} {0.01}{x_{i}} + \\epsilon\\ \\text{where}\\ \\epsilon \\sim \\mathcal{N}(0, {0.01}^{2})\n",
    "$$\n",
    "- Noise term $\\epsilon$ obeys a normal distribution with mean of $0$ and standard deviation of $0.01$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fdc399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_data(W: torch.Tensor, b: torch.Tensor, num_samples: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Generate Data: Xw + b + noise.\"\"\"\n",
    "    X: torch.Tensor = torch.normal(0, 1, (num_samples, len(W)))\n",
    "    y: torch.Tensor = X @ W + b\n",
    "    y += torch.normal(0, 1e-2, y.shape)\n",
    "    return X, y.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaa0fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, test_size, num_inputs = 20, 100, 200\n",
    "true_w, true_b = torch.ones((num_inputs, 1)) * 1e-2, 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bb80f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data: Tuple[torch.Tensor, torch.Tensor] = generate_random_data(true_w, true_b, train_size)\n",
    "test_data: Tuple[torch.Tensor, torch.Tensor] = generate_random_data(true_w, true_b, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2680624",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8ba4be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data: Dict[str, torch.Tensor] = {\n",
    "    'train_data': train_data,\n",
    "    'test_data': test_data,\n",
    "    'num_inputs': num_inputs,\n",
    "}\n",
    "\n",
    "save_path: str = os.path.join('..', '..', 'data', 'weight_decay')\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "with open(os.path.join(save_path, 'weight_decay.pkl'), 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
